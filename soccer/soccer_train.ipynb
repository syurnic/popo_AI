{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe123df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7535fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0431304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.  3.  0.  0. 10.  3.  0.  0. 40.  3.  0.  0.] {'winner': None}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import soccer_env\n",
    "\n",
    "env = gym.make(\"SoccerEnv\", render_mode=\"rgb_array\")\n",
    "env = gym.wrappers.FlattenObservation(env)\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "frame = env.render()\n",
    "plt.imshow(frame)\n",
    "\n",
    "print(state, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fdfe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.0000, 0.0000, 0.0000, 0.2000, 0.1000, 0.0000, 0.0000, 0.6000,\n",
       "         0.0000, 0.0000, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE_SCALE = np.array([50, 30, 30, 30, 50, 30, 30, 30, 50, 30, 30, 30])\n",
    "STATE_SCALE = torch.tensor(np.ones_like(STATE_SCALE) / STATE_SCALE, device=device).unsqueeze(0)\n",
    "\n",
    "def preprocess_state(state, label):\n",
    "    state = state.clone().detach()\n",
    "\n",
    "    state *= STATE_SCALE\n",
    "    if label == \"Player1\":\n",
    "        state[:, 0:2] -= state[:, 4:6]\n",
    "        state[:, 8:10] -= state[:, 4:6]\n",
    "    if label == \"Player2\":\n",
    "        state[:, 0:2] -= state[:, 8:10]\n",
    "        state[:, 4:6] -= state[:, 8:10]\n",
    "    \n",
    "    return state\n",
    "\n",
    "preprocess_state(torch.tensor(state, device=device).unsqueeze(0), \"Player1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a2f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions, label):\n",
    "        super(DQN, self).__init__()\n",
    "        d_model = 5\n",
    "        self.layer1 = nn.Linear(n_observations, d_model)\n",
    "        self.layer2 = nn.Linear(d_model, d_model)\n",
    "        self.layer3 = nn.Linear(d_model, n_actions)\n",
    "\n",
    "        self.label = label\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = preprocess_state(x, self.label)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dc7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE는 리플레이 버퍼에서 샘플링된 트랜지션의 수입니다.\n",
    "# GAMMA는 이전 섹션에서 언급한 할인 계수입니다.\n",
    "# EPS_START는 엡실론의 시작 값입니다.\n",
    "# EPS_END는 엡실론의 최종 값입니다.\n",
    "# EPS_DECAY는 엡실론의 지수 감쇠(exponential decay) 속도 제어하며, 높을수록 감쇠 속도가 느립니다.\n",
    "# TAU는 목표 네트워크의 업데이트 속도입니다.\n",
    "# LR은 ``AdamW`` 옵티마이저의 학습율(learning rate)입니다.\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.8\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "class ModelSettings:\n",
    "    def __init__(self, model, n_observations, action_space, **kwargs):\n",
    "        self.action_space = action_space\n",
    "        n_actions = action_space.n\n",
    "\n",
    "        self.policy_net = model(n_observations, n_actions, **kwargs).to(device)\n",
    "        self.target_net = model(n_observations, n_actions, **kwargs).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "\n",
    "        self.steps_done = 0\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "                # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "                # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "                return self.policy_net(state).max(1).indices.view(1, 1)\n",
    "        else:\n",
    "            return torch.tensor([[self.action_space.sample()]], device=device, dtype=torch.long)\n",
    "    \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "        # 전환합니다.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "        # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "        # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "        # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "        # max(1).values로 최고의 보상을 선택하십시오.\n",
    "        # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1).values\n",
    "        # 기대 Q 값 계산\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch.squeeze(1)\n",
    "\n",
    "        # Huber 손실 계산\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # 모델 최적화\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 변화도 클리핑 바꿔치기\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_net(self):\n",
    "        target_net_state_dict = self.target_net.state_dict()\n",
    "        policy_net_state_dict = self.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        self.target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "setting1 = ModelSettings(DQN, n_observations, env.action_space[0], label=\"Player1\")\n",
    "setting2 = ModelSettings(DQN, n_observations, env.action_space[1], label=\"Player2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "612eb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    ax.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42229887",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# (정책 네트워크에서) 최적화 한단계 수행\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43msetting1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m setting2\u001b[38;5;241m.\u001b[39moptimize_model()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 목표 네트워크의 가중치를 소프트 업데이트\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# θ′ ← τ θ + (1 −τ )θ′\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 82\u001b[0m, in \u001b[0;36mModelSettings.optimize_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(state_action_values, expected_state_action_values\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# 모델 최적화\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# 변화도 클리핑 바꿔치기\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\torch\\_dynamo\\decorators.py:47\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     45\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:300\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\inspect.py:949\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    947\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action1 = setting1.select_action(state)\n",
    "        action2 = setting2.select_action(state)\n",
    "        observation, reward, terminated, truncated, info = env.step((action1.item(), action2.item()))\n",
    "\n",
    "        if False:\n",
    "            frame = env.render()\n",
    "            ax = plt.subplot(2, 2, 2)\n",
    "            ax.imshow(frame)\n",
    "            plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "            if is_ipython:\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "        #if t == 300:\n",
    "        #    truncated = True\n",
    "\n",
    "        d1 = torch.norm(state[0][0:2] - state[0][4:6]).item()\n",
    "        d2 = torch.norm(state[0][0:2] - state[0][8:10]).item()\n",
    "        \n",
    "        d3 = np.linalg.norm(observation[0:2] - observation[4:6])\n",
    "        d4 = np.linalg.norm(observation[0:2] - observation[8:10])\n",
    "\n",
    "        reward1 = int(info[\"winner\"] == \"Player1\") * 10\n",
    "        reward2 = int(info[\"winner\"] == \"Player2\") * 10\n",
    "        reward1, reward2 = (reward1 - reward2, reward2 - reward1)\n",
    "        reward1 += (d1 - d3)\n",
    "        reward2 += (d2 - d4)\n",
    "        reward = torch.tensor([reward1, reward2], device=device)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        setting1.memory.push(state, action1, next_state, reward[0].view(1, 1))\n",
    "        setting2.memory.push(state, action2, next_state, reward[1].view(1, 1))\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # (정책 네트워크에서) 최적화 한단계 수행\n",
    "        setting1.optimize_model()\n",
    "        setting2.optimize_model()\n",
    "\n",
    "        # 목표 네트워크의 가중치를 소프트 업데이트\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        setting1.update_target_net()\n",
    "        setting2.update_target_net()\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54d3a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b17bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
