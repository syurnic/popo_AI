{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe123df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7535fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0431304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.  3.  0.  0. 10.  3.  0.  0. 40.  3.  0.  0.] {'winner': None}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import soccer_env\n",
    "\n",
    "env = gym.make(\"SoccerEnv\", render_mode=\"rgb_array\")\n",
    "env = gym.wrappers.FlattenObservation(env)\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "frame = env.render()\n",
    "plt.imshow(frame)\n",
    "\n",
    "print(state, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a2f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 1)\n",
    "        self.layer2 = nn.Linear(1, 1)\n",
    "        self.layer3 = nn.Linear(1, n_actions)\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08dc7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE는 리플레이 버퍼에서 샘플링된 트랜지션의 수입니다.\n",
    "# GAMMA는 이전 섹션에서 언급한 할인 계수입니다.\n",
    "# EPS_START는 엡실론의 시작 값입니다.\n",
    "# EPS_END는 엡실론의 최종 값입니다.\n",
    "# EPS_DECAY는 엡실론의 지수 감쇠(exponential decay) 속도 제어하며, 높을수록 감쇠 속도가 느립니다.\n",
    "# TAU는 목표 네트워크의 업데이트 속도입니다.\n",
    "# LR은 ``AdamW`` 옵티마이저의 학습율(learning rate)입니다.\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.95\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "LOG = defaultdict(list)\n",
    "\n",
    "class ModelSettings:\n",
    "    def __init__(self, model, n_observations, action_space, debug):\n",
    "        self.action_space = action_space\n",
    "        n_actions = action_space.n\n",
    "\n",
    "        self.policy_net = model(n_observations, n_actions).to(device)\n",
    "        self.target_net = model(n_observations, n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "\n",
    "        self.steps_done = 0\n",
    "\n",
    "        self.debug = debug\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "                # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "                # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "                pred = self.policy_net(state)\n",
    "                if self.debug:\n",
    "                    LOG[\"pred\"].append(pred.numpy(force=True))\n",
    "                return pred.max(1).indices.view(1, 1)\n",
    "        else:\n",
    "            return torch.tensor([[self.action_space.sample()]], device=device, dtype=torch.long)\n",
    "    \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "        # 전환합니다.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "        # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "        # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "        # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "        # max(1).values로 최고의 보상을 선택하십시오.\n",
    "        # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1).values\n",
    "        # 기대 Q 값 계산\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch.squeeze(1)\n",
    "\n",
    "        # Huber 손실 계산\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "\n",
    "        # 모델 최적화\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 변화도 클리핑 바꿔치기\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        \n",
    "        if self.debug:\n",
    "            LOG[\"loss\"].append(loss.item())\n",
    "            LOG[\"reward\"].extend((item.action.item(), item.reward.item()) for item in transitions)\n",
    "            LOG[\"bias\"].append(self.policy_net.layer3.bias.numpy(force=True))\n",
    "            LOG[\"grad\"].append(self.policy_net.layer3.bias.grad.numpy(force=True))\n",
    "        \n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_net(self):\n",
    "        target_net_state_dict = self.target_net.state_dict()\n",
    "        policy_net_state_dict = self.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        self.target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "setting1 = ModelSettings(DQN, n_observations, env.action_space[0], debug=True)\n",
    "setting2 = ModelSettings(DQN, n_observations, env.action_space[1], debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "612eb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "\n",
    "    size = (2, 3)\n",
    "\n",
    "    ax = plt.subplot(*size, 1)\n",
    "\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    ax.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        ax.plot(means.numpy())\n",
    "    \n",
    "    ax = plt.subplot(*size, 2)\n",
    "    ax.plot(LOG[\"loss\"])\n",
    "\n",
    "    ax = plt.subplot(*size, 3)\n",
    "    ax.scatter([0] * len(LOG[\"pred\"]), list(x[0][0] for x in LOG[\"pred\"]), s=1)\n",
    "    ax.scatter([1] * len(LOG[\"pred\"]), list(x[0][1] for x in LOG[\"pred\"]), s=1)\n",
    "    ax.scatter([2] * len(LOG[\"pred\"]), list(x[0][2] for x in LOG[\"pred\"]), s=1)\n",
    "    ax.scatter([3] * len(LOG[\"pred\"]), list(x[0][3] for x in LOG[\"pred\"]), s=1)\n",
    "    ax.scatter([4] * len(LOG[\"pred\"]), list(x[0][4] for x in LOG[\"pred\"]), s=1)\n",
    "\n",
    "    ax = plt.subplot(*size, 4)\n",
    "    ax.scatter(list(x[0] for x in LOG[\"reward\"]), list(x[1] for x in LOG[\"reward\"]), s=1)\n",
    "\n",
    "    ax = plt.subplot(*size, 5)\n",
    "    ax.imshow(np.stack(LOG[\"bias\"][-300:]), aspect='auto', cmap='viridis', interpolation='none')\n",
    "\n",
    "    ax = plt.subplot(*size, 6)\n",
    "    ax.imshow(np.stack(LOG[\"grad\"][-300:]), aspect='auto', cmap='viridis', interpolation='none')\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42229887",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m setting2\u001b[38;5;241m.\u001b[39mupdate_target_net()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mplot_durations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     LOG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m     episode_durations\u001b[38;5;241m.\u001b[39mappend(t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 30\u001b[0m, in \u001b[0;36mplot_durations\u001b[1;34m(show_result)\u001b[0m\n\u001b[0;32m     27\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter([\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(LOG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlist\u001b[39m(x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m LOG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m]), s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m*\u001b[39msize, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLOG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLOG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m*\u001b[39msize, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     33\u001b[0m ax\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mstack(LOG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m300\u001b[39m:]), aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1461\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1464\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1465\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4575\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4572\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_unit_info([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, x), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)], kwargs)\n\u001b[0;32m   4573\u001b[0m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[0;32m   4574\u001b[0m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[1;32m-> 4575\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4576\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m   4577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\numpy\\ma\\core.py:6852\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[1;34m(self, a, *args, **params)\u001b[0m\n\u001b[0;32m   6849\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m   6850\u001b[0m     a, args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], a\n\u001b[1;32m-> 6852\u001b[0m marr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6853\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   6854\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(marr), method_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\numpy\\ma\\core.py:8132\u001b[0m, in \u001b[0;36masanyarray\u001b[1;34m(a, dtype)\u001b[0m\n\u001b[0;32m   8130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, MaskedArray) \u001b[38;5;129;01mand\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   8131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[1;32m-> 8132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmasked_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2859\u001b[0m, in \u001b[0;36mMaskedArray.__new__\u001b[1;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2857\u001b[0m         \u001b[38;5;66;03m# If data is a sequence of masked array\u001b[39;00m\n\u001b[0;32m   2858\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m-> 2859\u001b[0m             \u001b[43m[\u001b[49m\u001b[43mgetmaskarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2860\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mmdtype)\n\u001b[0;32m   2861\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2862\u001b[0m         \u001b[38;5;66;03m# If data is nested\u001b[39;00m\n\u001b[0;32m   2863\u001b[0m         mask \u001b[38;5;241m=\u001b[39m nomask\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2859\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2857\u001b[0m         \u001b[38;5;66;03m# If data is a sequence of masked array\u001b[39;00m\n\u001b[0;32m   2858\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m-> 2859\u001b[0m             [\u001b[43mgetmaskarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2860\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m data], dtype\u001b[38;5;241m=\u001b[39mmdtype)\n\u001b[0;32m   2861\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2862\u001b[0m         \u001b[38;5;66;03m# If data is nested\u001b[39;00m\n\u001b[0;32m   2863\u001b[0m         mask \u001b[38;5;241m=\u001b[39m nomask\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\numpy\\ma\\core.py:1424\u001b[0m, in \u001b[0;36mgetmaskarray\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, nomask)\n\u001b[0;32m   1421\u001b[0m get_mask \u001b[38;5;241m=\u001b[39m getmask\n\u001b[1;32m-> 1424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetmaskarray\u001b[39m(arr):\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;124;03m    Return the mask of a masked array, or full boolean array of False.\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m     mask \u001b[38;5;241m=\u001b[39m getmask(arr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action1 = setting1.select_action(state)\n",
    "        action2 = setting2.select_action(state)\n",
    "        observation, reward, terminated, truncated, info = env.step((action1.item(), action2.item()))\n",
    "\n",
    "        frame = env.render()\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('Env', frame_bgr)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        if t == 300:\n",
    "            truncated = True\n",
    "\n",
    "        d1 = torch.norm(state[0][0:2] - state[0][4:6]).item()\n",
    "        d2 = torch.norm(state[0][0:2] - state[0][8:10]).item()\n",
    "        \n",
    "        d3 = np.linalg.norm(observation[0:2] - observation[4:6])\n",
    "        d4 = np.linalg.norm(observation[0:2] - observation[8:10])\n",
    "\n",
    "        reward1 = int(info[\"winner\"] == \"Player1\") * 10\n",
    "        reward2 = int(info[\"winner\"] == \"Player2\") * 10\n",
    "        #reward1, reward2 = (reward1 - reward2, reward2 - reward1)\n",
    "        reward1 += (d1 - d3)\n",
    "        reward2 += (d2 - d4)\n",
    "\n",
    "        reward = torch.tensor([reward1, reward2], device=device)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        setting1.memory.push(state, action1, next_state, reward[0].view(1, 1).clone())\n",
    "        setting2.memory.push(state, action2, next_state, reward[1].view(1, 1).clone())\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # (정책 네트워크에서) 최적화 한단계 수행\n",
    "        setting1.optimize_model()\n",
    "        setting2.optimize_model()\n",
    "\n",
    "        # 목표 네트워크의 가중치를 소프트 업데이트\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        setting1.update_target_net()\n",
    "        setting2.update_target_net()\n",
    "\n",
    "        if done:\n",
    "            plot_durations()\n",
    "            LOG[\"pred\"] = []\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70098bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 1., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    setting1.policy_net.layer3.bias[0] = 0\n",
    "    setting1.policy_net.layer3.bias[1] = 0\n",
    "    setting1.policy_net.layer3.bias[2] = 1\n",
    "    setting1.policy_net.layer3.bias[3] = 0\n",
    "    setting1.policy_net.layer3.bias[4] = 0\n",
    "\n",
    "print(setting1.policy_net.layer3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee76c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_durations(show_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d3a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGhCAYAAABPr581AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9BElEQVR4nO3de3yU5Z3H/e9MIJkAyUDQZAY5RbRijKdQ0eCxipLVYq0+re6Kj9u6aFnsithaaKtZtrVR19VtLQV1W92XrI+223qgtbEsVjw0CCWixFAPGJRCEgqBSQQScOZ+/shBEpLJNfGee65JPu/XK39k5pt43Q535jfX0ec4jiMAAAAL+VPdAAAAgL5QqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGsltVCJRqO64447VFhYqOzsbE2ZMkU/+MEPdPiu/Y7j6M4771Q4HFZ2drZmzpyp9957L5nNAgAAaSKphco999yjZcuW6ac//ak2b96se+65R/fee68efPDBrsy9996rn/zkJ1q+fLlef/11jRw5UrNmzVJra2symwYAANKAL5mHEn7xi19UQUGBfv7zn3c9dtVVVyk7O1srVqyQ4zgaN26cbrvtNn3rW9+SJEUiERUUFOixxx7TNddc0+9/IxaLaceOHcrJyZHP50vWpQAAABc5jqOWlhaNGzdOfn/f/SbDktmIGTNm6OGHH9a7776rz33uc3rzzTf16quv6v7775ck1dXVqaGhQTNnzuz6mWAwqDPPPFNVVVW9FiptbW1qa2vr+n779u0qKipK5mUAAIAk2bZtm8aPH9/n80ktVBYtWqTm5mZNnTpVGRkZikajuuuuu3TttddKkhoaGiRJBQUF3X6uoKCg67meKioqtGTJkiMe37Ztm3Jzc12+AgAAkAzNzc2aMGGCcnJy4uaSWqj88pe/1P/8z//oiSee0EknnaSNGzdqwYIFGjdunK6//voB/c7Fixdr4cKFXd93Xmhubi6FCgAAaaa/aRtJLVS+/e1va9GiRV1DOCeffLI+/PBDVVRU6Prrr1coFJIkNTY2KhwOd/1cY2OjTjvttF5/Z1ZWlrKyspLZbAAAYImkrvrZv3//ERNkMjIyFIvFJEmFhYUKhUJavXp11/PNzc16/fXXVVpamsymAQCANJDUHpXZs2frrrvu0sSJE3XSSSfpjTfe0P3336+vf/3rktq7exYsWKAf/vCHOv7441VYWKg77rhD48aN0xVXXJHMpgEAgDSQ1ELlwQcf1B133KF//ud/1s6dOzVu3DjddNNNuvPOO7syt99+u/bt26cbb7xRe/fu1TnnnKPKykoFAoFkNg0AAKSBpO6j4oXm5mYFg0FFIhEm0wIAkCZM37856wcAAFiLQgUAAFiLQgUAAFgrqZNpAWCgojFH6+qatLOlVfk5AU0vzFOGn/O8gKGGQgWAdSpr6rVkZa3qI5+eoh4OBlQ+u0hlxeE4PwlgsGHoB4BVKmvqNW9FdbciRZIaIq2at6JalTX1KWoZgFSgUAFgjWjM0ZKVteptz4TOx5asrFU0lta7KgBIAIUKAGusq2s6oiflcI6k+kir1tU1edcoAClFoQLAGjtb+i5SBpIDkP4oVABYIz/H7OgM0xyA9EehAsAa0wvzFA4G1NciZJ/aV/9ML8zzslkAUohCBYA1Mvw+lc8ukqQjipXO78tnF7GfCjCEUKgAsEpZcVjL5pQoFOw+vBMKBrRsTgn7qABDDBu+AbBOWXFYFxeF2JkWAIUKADtl+H0qnTI21c0AkGIM/QAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGtRqAAAAGuxPBmAlaIxh31UAFCoALBPZU29lqysVX3k01OSw8GAymcXsTMtMMQw9APAKpU19Zq3orpbkSJJDZFWzVtRrcqa+hS1DEAqUKgAsEY05mjJylo5vTzX+diSlbWKxnpLABiMKFQAWGNdXdMRPSmHcyTVR1q1rq7Ju0YBSCkKFQDW2NnSd5EykByA9EehAsAa+TkBV3MA0h+FCgBrTC/MUzgYUF+LkH1qX/0zvTDPy2YBSCEKFQDWyPD7VD67SJKOKFY6vy+fXcR+KsAQQqECwCplxWEtm1OiULD78E4oGNCyOSXsowIMMWz4BsA6ZcVhXVwUYmdaABQqAOyU4fepdMrYVDcDGLJsOcaCQgUAAHRj0zEWzFEBAABdbDvGgkIFAABIsvMYCwoVAAAgyc5jLChUAACAJDuPsaBQAQAAkuw8xoJCBQAASLLzGAsKFQAAIMnOYywoVAAAQBfbjrFgwzcAANCNTcdYUKgAAIAj2HKMBUM/AADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWhQqAADAWkkvVLZv3645c+Zo7Nixys7O1sknn6w///nPXc87jqM777xT4XBY2dnZmjlzpt57771kNwsAAKSBpBYqe/bs0dlnn63hw4fr97//vWpra/Uf//EfGjNmTFfm3nvv1U9+8hMtX75cr7/+ukaOHKlZs2aptbU1mU0DAABpwOc4jpOsX75o0SK99tpreuWVV3p93nEcjRs3Trfddpu+9a1vSZIikYgKCgr02GOP6Zprrun3v9Hc3KxgMKhIJKLc3FxX2w8AAJLD9P07qT0qzz33nD7/+c/rK1/5ivLz83X66afrkUce6Xq+rq5ODQ0NmjlzZtdjwWBQZ555pqqqqnr9nW1tbWpubu72BWDwicYcVW3ZrWc3blfVlt2KxpL2mQpAL2y5B4cl85d/8MEHWrZsmRYuXKjvfve7Wr9+vf7lX/5FmZmZuv7669XQ0CBJKigo6PZzBQUFXc/1VFFRoSVLliSz2QBSrLKmXktW1qo+8ukQcDgYUPnsIpUVh1PYMmBosOkeTGqPSiwWU0lJiX70ox/p9NNP14033qi5c+dq+fLlA/6dixcvViQS6fratm2biy0GkGqVNfWat6K62x9ISWqItGreimpV1tSnqGXA0GDbPZjUQiUcDquoqKjbYyeeeKI++ugjSVIoFJIkNTY2dss0NjZ2PddTVlaWcnNzu30BGByiMUdLVtaqtw7mzseWrKxlGAhIEhvvwaQWKmeffbbeeeedbo+9++67mjRpkiSpsLBQoVBIq1ev7nq+ublZr7/+ukpLS5PZNAAWWlfXdMSnuMM5kuojrVpX1+Rdo4AhxMZ7MKlzVG699VbNmDFDP/rRj/TVr35V69at08MPP6yHH35YkuTz+bRgwQL98Ic/1PHHH6/CwkLdcccdGjdunK644opkNg2AhXa2mG1LYJoDkBgb78GkFipnnHGGnn76aS1evFj/9m//psLCQv3nf/6nrr322q7M7bffrn379unGG2/U3r17dc4556iyslKBQCCZTQNgofwcs/veNAcgMTbeg0ndR8UL7KMCDB7RmKNz7nkxbtdzOBjQq9+5UBl+n4ctA4aGznuwIdLa6zwVn6SQS/egFfuoAEAiMvw+XX5q/KWPl58apkgBkiTD71P57PZFMD3vss7vy2cXeXoPUqgAsEY05ui5N+MvfXzuzXpW/QBJVFYc1rI5JQoFuw/vhIIBLZtT4vk+KkmdowIAiehvxYH06YqD0iljPWoVMPSUFYd1cVFI6+qatLOlVfk5AU0vzEtJbyaFCgBr2LjiABiqMvw+Kz4QMPQDwBo2rjgAkFoUKgCsMb0wT+Fg4IhJfJ18al/1M70wz8tmAUghChUA1rBxxQGA1KJQAWAV21YcAEgtJtMCsI5NKw4ApBaFCgAr2bLiAEBqMfQDAACsRaECAACsxdAPACtFYw5zVABQqACwT2VNvZasrO22nX44GFD57CJW/QBDDEM/AKxSWVOveSuqjzjzpyHSqnkrqlVZE//QQgCDC4UKAGtEY46WrKxVb2cjdz62ZGUtpycDQwiFCgBr9Hd6sqNPT08GMDRQqACwBqcnA+iJybQArMHpyYA9bFl5R6ECwBqdpyc3RFp7nafiU/uZP5yeDCSXTSvvGPoBYA1OTwZSz7aVdxQqAKzC6clA6ti48o6hHwDW4fRkIDUSWXnn1aGhFCq9sGUCETCUcXoy4D0bV95RqPRg0wQiAAC8ZOPKO+aoHMa2CUQAAHipc+VdX2MIPrV/ePdy5R2FSgcbJxABAOAlG1feUah0YOtuAADsW3nHHJUONk4gAgAgFWxaeUeh0sHGCUTAUMbqOyC1bFl5R6HSga27AXuw+g5AJ+aodLBxAhEwFLH6DsDhKFQOY9sEImCoYfUdgJ4Y+unBpglEwFBj4/bdAFKLQqUXtkwgAoYaVt8B6ImhHwDWYPUdgJ4oVABYw8btuwGkFoUKAGuw+g5ATxQqAKzC6jsAh2MyLQDrsPoOQCcKFQBWYvUdAImhHwAAYDEKFQAAYC0KFQAAYC0KFQAAYC0KFQAAYC0KFQAAYC0KFQAAYC0KFQAAYC0KFQAAYC12pgVgpWjMYQt9ABQqAOxTWVOvJStrVR9p7XosHAyofHYRhxICQwxDPwCsUllTr3krqrsVKZLUEGnVvBXVqqypT1HLAKQChQoAa0RjjpasrJXTy3Odjy1ZWatorLcEgMGIQgWANdbVNR3Rk3I4R1J9pFXr6pq8axSAlPKsULn77rvl8/m0YMGCrsdaW1s1f/58jR07VqNGjdJVV12lxsZGr5oEwDI7W/ouUgaSA5D+PClU1q9fr4ceekinnHJKt8dvvfVWrVy5Ur/61a+0Zs0a7dixQ1deeaUXTQJgofycgKs5AOkv6YXKxx9/rGuvvVaPPPKIxowZ0/V4JBLRz3/+c91///268MILNW3aND366KP605/+pLVr1ya7WQAsNL0wT+FgQH0tQvapffXP9MI8L5sFIIWSXqjMnz9fl112mWbOnNnt8Q0bNujQoUPdHp86daomTpyoqqqqZDcLgIUy/D6Vzy6SpCOKlc7vy2cXsZ8KMIQkdR+VJ598UtXV1Vq/fv0RzzU0NCgzM1OjR4/u9nhBQYEaGhr6/J1tbW1qa2vr+r65udm19gJIvbLisJbNKTliH5UQ+6gAQ1LSCpVt27bplltu0apVqxQIuDeeXFFRoSVLlrj2+wDYp6w4rAunFujxqq36sGm/JuWN0HWlk5U5jIWKwFDjcxwnKRsSPPPMM/ryl7+sjIyMrsei0ah8Pp/8fr9eeOEFzZw5U3v27OnWqzJp0iQtWLBAt956a6+/t7celQkTJigSiSg3NzcZlwLAY+xMCwx+zc3NCgaD/b5/J61H5aKLLtKmTZu6Pfa1r31NU6dO1Xe+8x1NmDBBw4cP1+rVq3XVVVdJkt555x199NFHKi0t7fP3ZmVlKSsrK1nNBpBinTvT9vwE1bkz7bI5JRQrwBCStEIlJydHxcXF3R4bOXKkxo4d2/X4DTfcoIULFyovL0+5ubn65je/qdLSUp111lnJahYAi/W3M61P7TvTXlwUYkItMESk9FDCBx54QH6/X1dddZXa2to0a9Ys/exnP0tlkwCkUCI705ZOGetdwwCkjKeFyksvvdTt+0AgoKVLl2rp0qVeNgOApdiZFkBPTKEHYA12pgXQE4UKAGt07kwbDzvTAkMLhQoAa2T4fbr81Pgrei4/NcxEWmAIoVABYI1ozNFTf/5r3MxTf/6rorGkbP8EwEIUKgCssXbLbu3dfyhuZu/+Q1q7ZbdHLQKQahQqAKxR9cEuV3MA0h+FCgCLmM49YY4KMFRQqACwxpmGq3lMcwDSH4UKAGv4fWY9JaY5AOmPQgWANXbta+s/lEAOQPqjUAFgjbzsTFdzANIfhQoAa/ylscXVHID0R6ECwBofNe1zNQcg/VGoAAAAa1GoALDGaRPGuJoDkP4oVABYY9zobFdzANIfhQoAa0wvzFM4GIibCQcDms6Gb8CQQaECwBoZfp/KZxf1uUG+T1L57CJl+NnwDRgqKFQAWKWsOKwbzytUz1rE75NuPK9QZcXh1DQMQEpQqACwSmVNvR5+uU4xp/vjMUd6+OU6VdbUp6ZhAFKCQgWANaIxR0tW1sqJk1myslbRnlUMgEGLQgWANdbVNak+0trn846k+kir1tU1edcoAClFoQLAGjtb+i5SBpIDkP6GpboBANDpqJFZruaQWtGYo3V1TdrZ0qr8nPZl5azYQqIoVABYY1/bJ67mkDqVNfVasrK221BeOBhQ+ewiVm4hIQz9ALDGj36/2dUcUqOypl7zVlQfMd+oIdKqeSuqWbmFhFCoALBG5MBBV3PwXryVW52PsXILiaBQAWCNsSMyXc3Be6zcGjyiMUdVW3br2Y3bVbVld8qKS+aoYFBiEl96+sKJBXr/lTqjHOzEyq3BwaY5RhQqGHRsusGQmKxhZp28pjl4Lz8n/qGSiebgvc45Rj37TzrnGC2bU+Lp31LudgwqTOJLb2cWjnU1B+91noAd72BJTsC2l41zjChUMGjYeIMhMX6f2fCcaQ7e6zwBu6+7zBEnYNvMxjlGFCoYNGy8wZCYXfvaXM0BSIyNc4woVDBo2HiDITFHjTLcmdYwB+919mzGQ8+mvWzcHZpCBYMGk/jSXyxq9uZlmoP3+uvZlOjZtJrpiJyHI3cUKhg0mMSX/tbW7XY1B+81RA64moO3dn1sOPxqmHMDhQoGjc5JfNKRxX7n90zis9v2vWZvXqY5eK9pn9muwaY5eMvGnmkKFQwqZcVhLZtTolCw+00UCgY8X/uPxDmGIzqmOXgvz3D+kGkO3rKxZ5oN3zDolBWHdXFRiJ1p05DjxFzNwXuhXLNP2qY5eKuzZ3reimr5pG7LzFPVM02PCgalDL9PpVPG6kunHaPSKWMpUtKEz2f2J8k0B+91fiKPh7lidrOtZ5oeFQDWOGZ0tqs5eO/wT+SSHZ/IkTibeqYpVABYY1RWhqs5pEbnJ/KeZ26FOHMrrXT2TKcahQoAa7y2ZZdx7p8vPD7JrcFnUVYc1oVTC/R41VZ92LRfk/JG6LrSycrkQEkkiEIFgDWaWz9xNYfUqayp178+97Yamj/db+ORVz7Qv15+Ej0qaeLgJzErCk0KFQDWOHX8aG3a3myUg70qa+r1jY45KodraG7TN1ZUazlbBViv4vlaPfJKnQ4/6eCu5zdr7rmFWnxpkadtoQ8OgDUW/d2JrubgvWjM0aLfbIqbWfSbTZz1Y7GK52v10MvdixRJijnSQy/XqeL5+Gc5uY1CBYA1Nm2PuJqD99Zu2a29+w/Fzezdf0hrt3AMgo0OfhLTI6/Uxc088kqdDn7i3V5GFCoArMEJ2Omv6gOzCdGmOXjr8aqtR/Sk9BRz2nNeYY4KBqVozLFi/T8S03rA7KAz0xxSwcLjd2Hsw6b9rubcQKHSC97k0ltlTf0R+zeE2b8hLSx6drNx7urSY5PcGgxE6ZSx+ukf3zfKwT6T8ka4mnMDhUoPvMmlt8qaes1bUa2ePZcNkVbNW1HNwYSWM51eyTRMe5117FiNHjE87jyVMSOG66xjKVRsdF3pZN31/Oa4wz9+X3vOK8xROUznm9zhRYr06ZtcZU19iloGE9GYoyUra3t9E+t8bMnKWlYbAEmU4ffp7itPjpupuPJkeqktlTnMr7nnFsbNzD230NP9VChUOvAml/7W1TUdUWQezpFUH2nVurom7xqFhFxwbI6rOaRGWXFYy+eUHHFCcjgYYA+VNLD40iLddF6hetaSfp9003ne76PC0E+HRN7kGFu1EytG0t9JE/P10gctRjnYzaZD7ZC40yeO0dGjdqix5dOJ60ePytLpE8d43hZ6VDrwJpf+8nPiHy2faA7eM523wPwGIHk6p0EcXqRI0s6WtpRMg6BHpQNvculvemGewsGAGiKtvQ7h+dR+euv0wjyvmwZDsajZ0KppDqnDwoT01N80CJ/ap0FcXBTyrHcsqT0qFRUVOuOMM5STk6P8/HxdccUVeuedd7plWltbNX/+fI0dO1ajRo3SVVddpcbGxmQ2q1fTC/M0esTwuJkxI4bzJmexDL9P5bPbx0573j6d35fPLqLr2WK/2fhXV3NIDRYmpC8b5/oltVBZs2aN5s+fr7Vr12rVqlU6dOiQLrnkEu3bt68rc+utt2rlypX61a9+pTVr1mjHjh268sork9msAeMznP3KisNaNqdEoWD3nq9QMMDS5DSwfa/Z0KppDt5jYUJ6s3EaRFKHfiorK7t9/9hjjyk/P18bNmzQeeedp0gkop///Od64okndOGFF0qSHn30UZ144olau3atzjrrrGQ2r5t1dU1G51MwmdZ+TOJLX+PHZOvPH+4xysFOLExIb0eNzHI15wZPJ9NGIu0HieXltQ+fbNiwQYcOHdLMmTO7MlOnTtXEiRNVVVXlZdOsrCIxcBl+n0qnjNWXTjtGpVPGUqSkiS+eMs7VHLzH39L0FnMM54kZ5tzgWaESi8W0YMECnX322SouLpYkNTQ0KDMzU6NHj+6WLSgoUENDQ6+/p62tTc3Nzd2+3MBkWiD1Vr1tNnfBNAfvHTXK8BO5YQ7eer3O7FRr05wbPCtU5s+fr5qaGj355JOf6fdUVFQoGAx2fU2YMMGV9nWuGIknzIoRIKnWvPc3V3NIAc5BSHP2HSrpSaFy880367e//a3++Mc/avz48V2Ph0IhHTx4UHv37u2Wb2xsVCgU6vV3LV68WJFIpOtr27ZtrrQxw+/T5afGn2h5+alhhhCAJDr4idm7l2kO3tu1z+xka9McvGU6b8jL+UVJLVQcx9HNN9+sp59+Wi+++KIKC7ufHzBt2jQNHz5cq1ev7nrsnXfe0UcffaTS0tJef2dWVpZyc3O7fbkhGnP03Jvxu5Ofe7OemeppIhpzVLVlt57duF1VW3bzuqWJkVkZrubgPYbR01uJ4c6zpjk3JHXVz/z58/XEE0/o2WefVU5OTte8k2AwqOzsbAWDQd1www1auHCh8vLylJubq29+85sqLS31dMWP1P9MdYmZ6umCjabSV1aGWY+laQ7e6xxGj/f3lGF0ez3x+ofGuRvOPTbJrWmX1B6VZcuWKRKJ6IILLlA4HO76euqpp7oyDzzwgL74xS/qqquu0nnnnadQKKTf/OY3yWxWr5ipPjiw0VR6ywmYfXYyzcF7DKOntw+b9ruac0NS73bHYPlSIBDQ0qVLtXTp0mQ2pV90V6Y/G7d+RmKiMXdz8J7pMPrtZSdyH1poUt4IV3Nu4FDCDtMmjZGvn3vG52vPwU42bv2MxHywy+xTmmkO3ktkGB32ua50cr/reXwdOa9QqHRYX9ek/jqAHKc9BzsxfJf+ojGzrhLTHLzHfZjeTHu5vOwNo1Dp8NoWs30ZTHPwHsN36S97uNlqHtMcvJc3ItPVHLz1x807+93ixunIeYVCpcMOw0POTHPwXudqg77qfJ9YbWC740OjXM3Be39pMNst3DQHb/3w+bddzbmBQqXDMYaHnJnm4L0Mv0/ls4skHblnYuf35bOLmMBnsc8VmO2LZJqD97btOeBqDt7a/fFBV3NuoFDpMGPKUa7mkBplxWEtm1OiUI/jEELBgJbNKWEfFct9p+xEV3Pwno2rRmBu7EizITnTnBvYjKDDWceO1YjMDO0/GO0zMzIzQ2cdy2ZvtisrDuviopDW1TVpZ0ur8nPah3voSbHfPS+8ZZz7wZdKktwaDMR1pZN11/ObFW8zaL/P21UjMHfHpUW6YcUGo5xX6FE5TOaw+P87+nse9sjw+1Q6Zay+dNoxKp0yliIlTTxeZbYhn2kO3ssc5tfccwvjZuaeW8jfU0tdUFSg/v5c+n3tOa/wL6XDurom7d1/KG5mz/5DrP0HgH4svrRIN51X2OtcsZvOK9RiDz+NIzEZfp9+dm383sqfXVvC8uRUaGg2W81jmgOAoa7nJpr9baoJO5QVh7V8TomOHjm82+P5o4ZreQrm+jFHpUPTx2ZHjpvmACTu+nMK9N+vNhrlYK+K52v10Mt1Rzwec9T1OL0qdisrDuv8z+XrR8/Xauvu/Zo8doS+e2mRsjO938OIHpUOeYYzmE1zABJ356XTXM3Bewc/iemRV44sUg73yCt1OvgJuwvbrOL5Wp1UXqnH136kV97bpcfXfqSTyitV8Xyt522hUOkQCprtj2KaAzAwo0cMj/v8mH6eR2o9XrU17oofqb1n5fGqrZ60B4nr7BHr+Tp29oh5XaxQqHTgUEIg9ZjUnv7qdu9zNQdv2dgjRqHSYf1Ww0MJt/IHEkiWHXvMTkU2zcF7pvNlmVdrJxt7xChUOlRt2e1qDkDi3ti219UcvHf6BLNeZ9McvLV1t9mHANOcGyhUuvR3XmSiOQCJamwxW/5vmoP3CoJmp5Ob5uA1+94LKVQ6nDnZbGt80xyAxI3MNNsxwTQH78X6GzdIMAdvnXJM0NWcGyhUOvgzzEZMTXMAEvflU49xNQfvvW440dk0B2/tPRB/MnuiOTdQqHTYZbiRm2kOwACY/kXiL5fF7Bs6gLk9+8wKENOcG7jdO+TnmI2XmuYAJO6pP29zNQfvnVloOIxumIO3/mq4os405wYKlQ7TC/OMNpqaXpjnUYuAoeeVd/rfPj+RHFKADpW09v7OFldzbqBQOUx/G9iw5XP6iMYcVW3ZrWc3blfVlt2KMnEvLew/ZPY6mebgvaq6Xa7m4K39h6Ku5tzA1PkOaz/Yrf0H4/+P33cwqrUf7NbZxx3lUaswEJU19Vqyslb1kU+XsIaDAZXPLvL81E8kZkRmhlra+v8DOCIFB6PBzLamA67m4K1wbra27u7/tQnnenecDD0qHdjwbXCorKnXvBXV3YoUSWqItGreimpV1tSnqGUw8XcnhVzNwXt1uwy30DfMwVuBTLOywDTnBgqVLgysprtozNGSlbW9vkJOx9eSlbUMA1mMiZhAaplOceCsnxQ4/ZjRrubgvXV1TUf0pPRUH2nlQDuLff+5Gldz8N4JoZGu5uCtTMO9wkxzbqBQ6fD/bfjI1Ry819Bstq26aQ7eaz1k9inNNAfvffA3s2Wrpjl4q7HFbK8w05wbKFQ6bNtj9uZlmoP3mgw34zPNwXtZhnNkTXPwXkOz2f1lmoO3WlrNVvOY5txAodJh4hizGcymOXgvb2Smqzl47++KDSfTGubgvXGGhw2a5uCtE0I5rubcQKHS4YGrT3c1B++FgmZFpGkO3huZbVZEmubgvV/843RXc/DWfxq+x5nm3ECh0mFUYJhOGZ8bN3PK+FyNCrD1jK2mF+Yp3M+ntHAwwO7CFjvG8FO2aQ7eC44Yrklj438YmDQ2W8F+dgJHamRnZmiYP/5E2WF+n7I93MuIQuUwz918bp/Fyinjc/Xczed63CIkIsPvU/nsIvV1i/kklc8uUkY/NyFS599feNfVHFJjzbcv1NGjeu/1OnpUptZ8+0KPWwRT6+qa9Ek/Wzh8EnM8XT1J90APz918rj5u/US3PvWGPtpzQBPHZOuBq0+nJyVNlBWHtWxOCTvTpinTtTys+bFbZU29dn18sNfndn18UJU19dyLltpheNhge86b/Yx49+3FqMAwPXL9GaluBgaorDisi4tCWlfXpJ0trcrPaR/uoScFSL54Gy9Kn268eHFRiHvSQhs+2mOcu+rzE5LcmnYUKhiUMvw+lU5h91LAa4lsvMg9ap93G81ORTbNuYE5KgAA12w3HDowzQEUKgCs8d+GQ66mOXjvhbcbXM3BWxcXme1RZJpzA4UKAGucc8LRrubgvf2HzHYsNc3BW/9v6WRXc26gUOlFNOaoastuPbtxu6q27Oa0XcAjTX2sFBloDt479iizwwZNc/DWxm17Xc25gcm0PVTW1LO0FUiRL//sVePcq4suSnJrMBDfumSqHl/b/+Gt37pkqgetQaISm2PkzWRoelQOU1lTr3krqo+Ysd4QadW8FdWqrKlPUcuAoaFp3yFXc/De/27Y5moO3qp82+x9zjTnBgqVDvHW/nc+tmRlLcNAQBLljTTbVt00B+992GT2idw0B2/V742/tDzRnBsoVDr0t/bf0adr/2E/5hmlp6dunOFqDt4bb3jop2kOYI5Kh50tZtWhaQ6pwzyj9JVIt/MN5x6b5NZgIA7GzFbzmObgrRzD42JMc26gR6XDUaOyXM0hNZhnlN4YNkh/z725w9UcvHXwkNlJWqY5N1CodIhFzYYGTHPwXn/zjDrPGGEYyF4TxpgNB5jm4L3Wtk9czcFbBw6ZvS6mOTdQqHR4fetuV3PwXiJnjMBOU0O5rubgvf2Gn7RNc/DW3wz3KDLNuYFCpYvpKZ6c9mmr+r0HXM3Be037DTd8M8zBe6YnInNyMkxRqHQwPcWT0z7t9cY2s+PJTXPwXn5OwNUcvBfMNls6bpqDtybkjXA15wYKlQ5nTM5zNQfvmc48YYaKvaYX5ikcDPTZb+lT+wqu6YXch7b6+jmFrubgravPmOBqzg0UKh3W1Da6moP3CseanR1imoP3Mvw+lc8uknTkIGvn9+Wzixg2sNio4WbLVk1z8NZf6s16nE1zbqBQ6fD9377tag7eu650svp7//L72nOwV1lxWMvmlCgU7D68EwoGtGxOCXvhWG7xM2+5moO3Hqva7mrODZS0HT42XCpnmoP3Mof5ddGJ+VpVu7PPzEUn5itzGPW57cqKw7pwaoEer9qqD5v2a1LeCF1XOpnXLg3sazNbzWOaAyhUOowLBvTezn1GOdgpGnO0fmv87sj1W/coGnMYOrBcZU29vv/0Ju067PDBZS+9rx9++WR6VCzn90kmWxVxC8IUH086PPFPpa7m4L21W3Zr7/74p+ru3X9Ia7ewF47NKmvq9Y0V1d2KFEnate+QvsHuwtYrPdZwBaVhDt5acInZJGfTnBusKFSWLl2qyZMnKxAI6Mwzz9S6des8b8P7f/vY1Ry8V/XBLldz8F405ugbK6rjZr6xoprdhS028SizZaumOXgrZ7jZqIFpzg0pL1SeeuopLVy4UOXl5aqurtapp56qWbNmaefOvucZJAOHEg4GbNqX7l54y6y3xDQH75VMGONqDt7KG5npas4NKS9U7r//fs2dO1df+9rXVFRUpOXLl2vEiBH6xS9+4Wk7Hnxuo6s5eC9vhNmUK9McvPftX290NQfvrXjRbDWPaQ7euvWXb7qac0NKC5WDBw9qw4YNmjlzZtdjfr9fM2fOVFVVVa8/09bWpubm5m5fbnjf8DBW0xy892+/+4urOXhv3yGzIR3THLz3huFRWqY5IKWFyq5duxSNRlVQUNDt8YKCAjU0NPT6MxUVFQoGg11fEyZ4tzseAADwVsqHfhK1ePFiRSKRrq9t27alukkAXDIiw90cgPSX0kLlqKOOUkZGhhobu29L39jYqFAo1OvPZGVlKTc3t9uXG04w/D9hmoP3TI844yg0e6267UJXc/DeJVPczQEpfdvNzMzUtGnTtHr16q7HYrGYVq9erdJSb/cref6Hl7qag/e+O/sEV3Pw3jF52crMiL8qKzPDp2Pysj1qERL18NzLXM3BW1t+ZPYeZ5pzQ8r7BxYuXKhHHnlE//3f/63Nmzdr3rx52rdvn772ta952o4Mv0/L55TEzSyfU8KOphabGjJb7miaQ2q8e9elfRYrmRk+vXsXHxZst/Xu+EVIf88jdWx8L0x5oXL11Vfrvvvu05133qnTTjtNGzduVGVl5RETbL3wz/8Tf6Op/p5Hak0vzNOwfm6eYX6fphfmedQiDNS7d12q126/ULmBDGX4pNxAhl67/UKKlDRxxg9XfabnkVommy56yYoNJW6++WbdfPPNKW1D3c59/Z5PEXPac4X5I71pFBJy4GBUn/TzIn4Sc3TgYFSjAlb800ccx+Rl661/LUt1M5Cgpo8P6m8fH4yb+dvHB9X08UHljfJu0zCYeWdHi3HuhHE5SW5Nu5T3qNii7MdrXM3Be7c+9YarOQCJu+bhP7mag7cuffBlV3NuoFDp0BY120DKNAfvfbTngKs5AInb2RK/NyXRHLxl+hbn5VshhUqHrH5WGiSag/cmjjFbCWKaA5C4/Byz4RzTHLxl44lpFCodfvfN81zNwXv3feU0V3MAEvfkjTNczcFb/35lsas5N1CodPjbvjZXc/Bebb3ZuU+mOQCJyxuVqaP7mSR79KhMJtJa6vISs2NpTHNuoFDpsLOl1dUcvMdrCNhh/fcv7rNYOXpUptZ//2KPWwRT67eanRZpmnMDazQ75OcEXM3Be0eNynI1B2Dg1n//YjV9fFDXPPwn7Ww5qPycTD154wx6UixXtWW3ce7s445KcmvaUah0mF6Yp3AwoIZIq3qbzOyTFAoG2CzMZqaz0Fm4BXgib1Sm/rDwglQ3Awmx7w8pQz8dMvw+lc8uknTkbObO78tnF7GFvsV2Gc4fMs0BwFBTeqxZL4lpzg0UKocpKw5r2ZwShYLdh3dCwYCWzSlRWXE4RS2DCYbvAOCzOWvKWI0eEf+M+dEjhuusKWM9ahFDP0coKw7r4qKQ1tU1aWdLq/Jz2od76Emx3/TCPI3IzND+g9E+MyMyMxi+A4A+ZPh9uvvKk+Oe53P3lSd7+p5IodKLDL9PpR5Wi3BHNObowKG+ixRJOnAoqmjMofAEgD6UFYe1fE6J/vW5t9XQ/OlQeSg3S/96+Umejy5QqGDQeLxqq5x+5nc5TnvuhnOP9aZRAJCGbBpdoFDBoPFh035XcwAwlNkyusBkWgwak/JGuJoDAKQehQoGjetKJ6u/Xkm/rz0HAEgPFCoYNDKH+XXRiflxMxedmK/MYfyzB4B0wV9sDBrRmKNVtTvjZlbV7lQ0xta0AJAuKFQwaNz2P1Wu5gAAqUehgkHjmbf3uJoDAKQey5N7EY05VqwdBwBgqKNQ6aGypt6a3fgAIJ3xoS+9HfwkpserturDpv2alDdC15VOTsliBAqVw1TW1Pd6vkFDc5u+saJayzmY0Gr/z6lH63/f/JtRDkByVdbUa8nKWtVHWrseCwcDKp9dxN/RNFDxfK0eeaVOh689uOv5zZp7bqEWX1rkaVuYo9IhGnO06Deb4mYW/WYTK0Ysds/VZ7iaAzAwlTX1mreiuluRIkkNkVbNW1Gtypr6FLUMJiqer9VDL3cvUiQp5kgPvVyniudrPW0PhUqHtVt2a+/+Q3Eze/cf0totuz1qERKV4ffplPG5cTOnjM+l6xlIomjM0ZKVtertI13nY0tW1vKhz1IHP4npkVfq4mYeeaVOBz+JedQiCpUuVR/scjUH7x04GNVbf22Om3nrr806cDD+CcsABm5dXdMRPSmHcyTVR1q1rq7Ju0bB2ONVW4/oSekp1nG4q1coVLqYfsrm07it7vrd267mACRuZ0vfRcpAcvCWjYe7Uqh0MD0h0oaTJNG7N/8acTUHIHH5OQFXc/CWjYe7Uqh0OOvYsRo9YnjczJgRw3XWsRQqtgoG4r9+ieYAJG56YZ7CwUCffc8+ta/+mV6Y52WzYMjGw10pVDpk+H26+8qT42YqrjyZiZgWm3vusa7mACQuw+9T+ez25as9/1p2fl8+u4i/pZbKHObX3HML42bmnlvo6X4qFCqHKSsOa/mcEoVyu3dJhoMB9lBJA+d87mhl9XPzZA3z65zPsY8KkExlxWEtm1OiULD739JQMKBl/C213uJLi3TTeYVH9Kz4fdJN53m/j4rPcZy0XiPW3NysYDCoSCSi3Nz4S1NNsZti+upr075OFJyAd/hbmt6SvTOt6fs3hQoGncqaepU/+7YaWzgGAQBsZfr+zRb6GHTKisO6uCjEJzkAGAQoVDAoZfh9LCUHgEGAybQAAMBaFCoAAMBaFCoAAMBaFCoAAMBaFCoAAMBaFCoAAMBaLE/GoPTRrv0q+/EaHTgUU/ZwvypvOV8Tj/LutE8AgDsoVDDoHPfd3+mT2Kff7z8U03n3/VHD/NL7P7osdQ0DACSMoR8MKj2LlMN9Emt/HgCQPuhRwaDx0a79fRYpnT6JtecYBgKSj0MJ4QYKFQwaZT9eY5yr/cHfJbk1wNBWWVOvJStrVR9p7XosHAyofHYRh4MiIQz9YNA4cKif7pQEcwAGprKmXvNWVHcrUiSpIdKqeSuqVVlTn6KWIR1RqGDQyB5u9s/ZNAcgcdGYoyUra+X08lznY0tW1ioa6y0BHIm/2Bg0Km8539UcgMStq2s6oiflcI6k+kir1tU1edcopDUKFQwax+Rlu5oDkLidLX0XKQPJARQqGDRMP6HxSQ5InvycgKs5gFU/GDR27D3gag5A4qYX5ikcDKgh0trrPBWfpFCwfaky7GbL8nIKFQwaG7ftMc5dNW18klsDDE0Zfp/KZxdp3opq+aRuxUrnW1z57CL2U7GcTcvLGfoBALiqrDisZXNKFAp2H94JBQNaNqeEfVQsZ9vycnpUMGhMHjvS1RyAgSsrDuviopAVQwcw19/ycp/al5dfXBTy7LWkRwWDxnWlk9XffeP3tecAJF+G36fSKWP1pdOOUemUsRQpacDG5eVJKVS2bt2qG264QYWFhcrOztaUKVNUXl6ugwcPdsu99dZbOvfccxUIBDRhwgTde++9yWgOhojMYX7NPbcwbmbuuYXKHEZ9DgC9sXF5eVKGfv7yl78oFovpoYce0nHHHaeamhrNnTtX+/bt03333SdJam5u1iWXXKKZM2dq+fLl2rRpk77+9a9r9OjRuvHGG5PRLAwBiy8tkiQ98kqdDt/40u9rL1I6nwcAHMnG5eU+x3E82cf43//937Vs2TJ98MEHkqRly5bpe9/7nhoaGpSZmSlJWrRokZ555hn95S9/Mf69zc3NCgaDikQiys3NTUrbkX4OfhLT41Vb9WHTfk3KG6HrSifTkwIA/YjGHJ1zz4v9Li9/9TsXfuahPNP3b88m00YiEeXlfbpuvqqqSuedd15XkSJJs2bN0j333KM9e/ZozJgxvf6etrY2tbW1dX3f3NycvEYjbWUO8+uGc49NdTMAIK3YuLzck4+Y77//vh588EHddNNNXY81NDSooKCgW67z+4aGhj5/V0VFhYLBYNfXhAkTktNoAACGINuWlyfUo7Jo0SLdc889cTObN2/W1KlTu77fvn27ysrK9JWvfEVz584dWCsPs3jxYi1cuLDr++bmZooVAABcZNPy8oQKldtuu03/+I//GDdz7LGfdrfv2LFDX/jCFzRjxgw9/PDD3XKhUEiNjY3dHuv8PhQK9fn7s7KylJWVlUizAQBAgjqXl6daQoXK0UcfraOPPtoou337dn3hC1/QtGnT9Oijj8rv7z7KVFpaqu9973s6dOiQhg8fLklatWqVTjjhhD7npwAAgKElKXNUtm/frgsuuEATJ07Ufffdp7/97W9qaGjoNvfkH/7hH5SZmakbbrhBb7/9tp566in9+Mc/7jasAwAAhrakrPpZtWqV3n//fb3//vsaP7774W+dq6GDwaD+8Ic/aP78+Zo2bZqOOuoo3XnnneyhAgAAuni2j0qysI8KemPL8eQAgN5Zt48K4BWbjicHAHw2bNWJQcW248kBAJ8NhQoGjf6OJ5fajyePxtJ6tBMAhhQKFQwaNh5PDgD4bChUMGjYeDw5AOCzoVDBoGHj8eQAgM+GQgWDxvTCPIWD8YuQcLB9qTIAID1QqGDQyPD7dPmp8ZcfX35qmP1UACCNUKhg0IjGHD33Zvzlx8+9Wc+qHwBIIxQqGDT6W/UjseoHANINhQoGDVb9AMDgQ6GCQYNVPwAw+FCoYNDoXPXT11RZn1j1AwDphkIFg0aG36fy2UWSdESx0vl9+ewiVv0AQBqhUMGgUlYc1rI5JQr12E8lFAxo2ZwSTk8GgDQzLNUNANxWVhzWxUUhratr0s6WVuXntA/30JMCAOmHQgWDUobfp9IpY1PdDADAZ8TQDwAAsBaFCgAAsBaFCgAAsBaFCgAAsBaFCgAAsBaFCgAAsBaFCgAAsBaFCgAAsBaFCgAAsFba70zrOI4kqbm5OcUtAQAApjrftzvfx/uS9oVKS0uLJGnChAkpbgkAAEhUS0uLgsFgn8/7nP5KGcvFYjHt2LFDOTk58vncO3SuublZEyZM0LZt25Sbm+va77XJYL9Gri/9DfZrHOzXJw3+a+T6Bs5xHLW0tGjcuHHy+/ueiZL2PSp+v1/jx49P2u/Pzc0dlP/4DjfYr5HrS3+D/RoH+/VJg/8aub6BideT0onJtAAAwFoUKgAAwFoUKn3IyspSeXm5srKyUt2UpBns18j1pb/Bfo2D/fqkwX+NXF/ypf1kWgAAMHjRowIAAKxFoQIAAKxFoQIAAKxFoQIAAKw1pAuVpUuXavLkyQoEAjrzzDO1bt26uPlf/epXmjp1qgKBgE4++WQ9//zzHrV04BK5xscee0w+n6/bVyAQ8LC1iXn55Zc1e/ZsjRs3Tj6fT88880y/P/PSSy+ppKREWVlZOu644/TYY48lvZ0Dlej1vfTSS0e8fj6fTw0NDd40OEEVFRU644wzlJOTo/z8fF1xxRV65513+v25dLkPB3J96XYPLlu2TKecckrXZmClpaX6/e9/H/dn0uX1kxK/vnR7/Xq6++675fP5tGDBgrg5r1/DIVuoPPXUU1q4cKHKy8tVXV2tU089VbNmzdLOnTt7zf/pT3/S3//93+uGG27QG2+8oSuuuEJXXHGFampqPG65uUSvUWrffbC+vr7r68MPP/SwxYnZt2+fTj31VC1dutQoX1dXp8suu0xf+MIXtHHjRi1YsED/9E//pBdeeCHJLR2YRK+v0zvvvNPtNczPz09SCz+bNWvWaP78+Vq7dq1WrVqlQ4cO6ZJLLtG+ffv6/Jl0ug8Hcn1Set2D48eP1913360NGzboz3/+sy688EJ96Utf0ttvv91rPp1ePynx65PS6/U73Pr16/XQQw/plFNOiZtLyWvoDFHTp0935s+f3/V9NBp1xo0b51RUVPSa/+pXv+pcdtll3R4788wznZtuuimp7fwsEr3GRx991AkGgx61zl2SnKeffjpu5vbbb3dOOumkbo9dffXVzqxZs5LYMneYXN8f//hHR5KzZ88eT9rktp07dzqSnDVr1vSZScf7sJPJ9aXzPdhpzJgxzn/913/1+lw6v36d4l1fur5+LS0tzvHHH++sWrXKOf/8851bbrmlz2wqXsMh2aNy8OBBbdiwQTNnzux6zO/3a+bMmaqqqur1Z6qqqrrlJWnWrFl95lNtINcoSR9//LEmTZqkCRMm9PvJId2k22s4UKeddprC4bAuvvhivfbaa6lujrFIJCJJysvL6zOTzq+hyfVJ6XsPRqNRPfnkk9q3b59KS0t7zaTz62dyfVJ6vn7z58/XZZdddsRr05tUvIZDslDZtWuXotGoCgoKuj1eUFDQ53h+Q0NDQvlUG8g1nnDCCfrFL36hZ599VitWrFAsFtOMGTP017/+1YsmJ11fr2Fzc7MOHDiQola5JxwOa/ny5fr1r3+tX//615owYYIuuOACVVdXp7pp/YrFYlqwYIHOPvtsFRcX95lLt/uwk+n1peM9uGnTJo0aNUpZWVn6xje+oaefflpFRUW9ZtPx9Uvk+tLx9XvyySdVXV2tiooKo3wqXsO0Pz0Z7iktLe32SWHGjBk68cQT9dBDD+kHP/hBClsGEyeccIJOOOGEru9nzJihLVu26IEHHtDjjz+ewpb1b/78+aqpqdGrr76a6qYkhen1peM9eMIJJ2jjxo2KRCL63//9X11//fVas2ZNn2/m6SaR60u312/btm265ZZbtGrVKqsn/Q7JQuWoo45SRkaGGhsbuz3e2NioUCjU68+EQqGE8qk2kGvsafjw4Tr99NP1/vvvJ6OJnuvrNczNzVV2dnaKWpVc06dPt/7N/+abb9Zvf/tbvfzyyxo/fnzcbLrdh1Ji19dTOtyDmZmZOu644yRJ06ZN0/r16/XjH/9YDz300BHZdHz9Erm+nmx//TZs2KCdO3eqpKSk67FoNKqXX35ZP/3pT9XW1qaMjIxuP5OK13BIDv1kZmZq2rRpWr16dddjsVhMq1ev7nPssbS0tFteklatWhV3rDKVBnKNPUWjUW3atEnhcDhZzfRUur2Gbti4caO1r5/jOLr55pv19NNP68UXX1RhYWG/P5NOr+FArq+ndLwHY7GY2traen0unV6/vsS7vp5sf/0uuugibdq0SRs3buz6+vznP69rr71WGzduPKJIkVL0GiZtmq7lnnzySScrK8t57LHHnNraWufGG290Ro8e7TQ0NDiO4zjXXXeds2jRoq78a6+95gwbNsy57777nM2bNzvl5eXO8OHDnU2bNqXqEvqV6DUuWbLEeeGFF5wtW7Y4GzZscK655honEAg4b7/9dqouIa6WlhbnjTfecN544w1HknP//fc7b7zxhvPhhx86juM4ixYtcq677rqu/AcffOCMGDHC+fa3v+1s3rzZWbp0qZORkeFUVlam6hLiSvT6HnjgAeeZZ55x3nvvPWfTpk3OLbfc4vj9fuf//u//UnUJcc2bN88JBoPOSy+95NTX13d97d+/vyuTzvfhQK4v3e7BRYsWOWvWrHHq6uqct956y1m0aJHj8/mcP/zhD47jpPfr5ziJX1+6vX696bnqx4bXcMgWKo7jOA8++KAzceJEJzMz05k+fbqzdu3arufOP/985/rrr++W/+Uvf+l87nOfczIzM52TTjrJ+d3vfudxixOXyDUuWLCgK1tQUOBceumlTnV1dQpabaZzOW7Pr85ruv76653zzz//iJ857bTTnMzMTOfYY491Hn30Uc/bbSrR67vnnnucKVOmOIFAwMnLy3MuuOAC58UXX0xN4w30dm2Sur0m6XwfDuT60u0e/PrXv+5MmjTJyczMdI4++mjnoosu6noTd5z0fv0cJ/HrS7fXrzc9CxUbXkOf4zhO8vprAAAABm5IzlEBAADpgUIFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABYi0IFAABY6/8HYatpcTo3AxsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = setting1.memory.sample(900)\n",
    "res = list((item.action.item(), item.reward.item()) for item in L)\n",
    "plt.scatter(list(x[0] for x in res), list(x[1] for x in res))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52b17bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6997, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1430, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9788, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3326, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3556, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3841, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5855, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8155, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4156, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4156, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3715, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4446, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.3500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2004, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0092, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9332, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8218, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3005, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1585, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9618, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1195, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5706, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0650, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4319, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3669, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7311, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7672, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8513, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9355, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5747, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2182, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5621, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.4218, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5347, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0317, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4498, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6894, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2070, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1923, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1255, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4995, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5877, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3380, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4155, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2289, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0620, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9121, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9528, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1190, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8167, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9124, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6910, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9723, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8283, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3604, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8889, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6097, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3830, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6433, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5982, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1550, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7526, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1248, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6195, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1071, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0719, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9030, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.3111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0898, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6030, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5311, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5768, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4314, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6430, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2185, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4893, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4731, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5091, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5679, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5621, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3162, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3481, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1958, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2944, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5544, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1992, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6779, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0942, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2113, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7777, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7142, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5132, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3520, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1708, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5176, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0958, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0163, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8754, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9959, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6623, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2155, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7012, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4309, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2072, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0054, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0332, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9152, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1199, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6391, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6370, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0427, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6924, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4311, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4688, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6481, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0474, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0929, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9297, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1870, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2142, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7959, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6314, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2248, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8621, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6436, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0355, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1516, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0182, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6623, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6258, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1550, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3700, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6152, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0199, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5222, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8722, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0310, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.3961, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7254, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7039, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3768, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7371, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6030, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6871, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5514, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5853, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1037, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2708, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3279, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3879, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8380, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8933, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9556, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8543, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6587, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9975, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1491, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6107, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6600, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3150, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1988, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8059, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0853, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5596, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5224, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3072, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4461, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5996, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4719, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5716, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7524, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1516, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0949, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4704, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7963, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0415, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6519, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2776, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6146, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2314, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2544, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6254, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9107, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8941, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0504, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9074, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7075, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9893, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1117, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4001, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2446, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1020, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0716, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0489, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8669, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8039, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1655, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4391, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4963, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1725, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9068, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4923, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9360, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7929, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7283, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5173, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(4.9346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4491, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9894, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9102, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7703, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9490, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7140, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0808, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7465, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5205, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8480, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2338, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1036, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2577, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6414, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7339, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6000, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8155, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5218, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0070, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6082, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6882, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9675, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0776, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4948, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1028, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3194, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(4.8100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2724, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1320, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2373, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7230, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5958, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8924, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5427, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2499, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0248, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2309, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9054, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8409, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4595, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3367, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3794, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5481, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1015, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7754, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7348, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5528, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7874, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0498, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7834, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1537, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3718, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2437, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5759, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9882, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5344, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5367, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5725, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2182, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1417, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4740, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8580, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9123, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8152, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9864, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9855, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5060, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0777, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1734, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0516, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3720, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7091, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3473, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5514, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8737, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6067, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0679, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0292, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4660, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5076, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2604, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3889, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8759, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9585, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5917, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7186, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6989, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8092, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1049, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0367, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0830, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9476, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4075, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4871, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0360, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0620, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1898, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2725, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8688, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5861, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5301, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7211, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5117, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9312, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5623, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6354, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3577, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5692, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6379, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7577, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.3594, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0525, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7071, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8644, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3660, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6675, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1616, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0890, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6262, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2479, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1030, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1506, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3341, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5420, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3311, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5363, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8060, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2528, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8673, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0015, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6927, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7780, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5953, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2245, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1029, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4304, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5283, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1437, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4175, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2715, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6499, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7728, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4226, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8996, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0050, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9437, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6354, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9537, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0700, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1846, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0004, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5542, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5167, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8736, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0304, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5072, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2825, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1075, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7126, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2505, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3365, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0721, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0485, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8995, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7215, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6438, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5473, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.0440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6434, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7397, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8102, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4992, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5231, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8682, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8300, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5532, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7139, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8701, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0467, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6479, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1354, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2929, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2727, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0449, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7145, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8380, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7648, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6126, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8948, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1388, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0706, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0963, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4649, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5455, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3141, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0628, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8834, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5131, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8163, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0961, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1047, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8124, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8230, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.0638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2400, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9785, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5297, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2200, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7309, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7989, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9373, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3872, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1371, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4123, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4160, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1481, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5258, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3125, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8726, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5182, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6054, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1076, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5997, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8410, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3870, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8748, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8430, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6428, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5461, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9520, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9720, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1944, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3808, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9916, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7780, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9231, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3136, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8230, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1872, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9141, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9139, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1532, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1279, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6193, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5118, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6004, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5014, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4932, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1455, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5480, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6731, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2231, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1729, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5397, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6777, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7917, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2015, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9877, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0716, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9732, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6501, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9204, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7513, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1751, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9194, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.6792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6855, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7513, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6593, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9360, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5123, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9237, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3817, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1683, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4720, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1490, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5777, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2854, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5893, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6655, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2302, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9050, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2511, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0620, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6304, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3988, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2750, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4407, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0079, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0776, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8872, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2660, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1603, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5313, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2763, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9759, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1473, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0459, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7882, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8048, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1348, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9001, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6582, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4063, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5688, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3524, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9740, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3421, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9687, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5644, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8769, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2855, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0577, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7716, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7923, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9012, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9591, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8808, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1417, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5828, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5700, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9593, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0827, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4160, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(10.4138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5992, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0528, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0753, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7594, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8753, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2020, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1338, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8125, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6029, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9302, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9246, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2063, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6012, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1899, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2961, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8874, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1870, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2020, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2231, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4176, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9708, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2344, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9759, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1975, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2283, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5309, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4110, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0995, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9912, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5920, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4364, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8596, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8099, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8175, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6199, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9479, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8703, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1739, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1989, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2889, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2657, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5068, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5482, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7725, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9402, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3320, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1276, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3718, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9213, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0015, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9660, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1754, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9978, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8504, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2710, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3495, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9861, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0391, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6694, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5418, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2692, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3417, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9683, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8137, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1037, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8855, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8620, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9765, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2738, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4137, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6117, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9870, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8436, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0982, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2953, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4944, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9186, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9355, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7371, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4331, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8581, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5048, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9942, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3590, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4193, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3400, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9292, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4513, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1621, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5254, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4237, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5933, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0728, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2006, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5516, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2145, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3326, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3008, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7657, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1594, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4544, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4070, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5687, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3841, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1407, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5640, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5604, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4732, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0303, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6596, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6613, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5467, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7460, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3310, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1654, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2862, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5352, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3732, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7963, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1834, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6700, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9754, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4724, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2348, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5912, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2489, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4304, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0190, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4489, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2222, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8941, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9694, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4435, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4617, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3418, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5081, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9659, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2300, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6462, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9887, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(4.5969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3737, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6736, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1312, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1779, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5014, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8136, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3525, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6243, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7675, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6008, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6521, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0591, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.0318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6890, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9532, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3592, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7258, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0501, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2669, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7958, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9068, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4526, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0723, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6312, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4060, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8213, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3491, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5136, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1841, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8706, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1666, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0683, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2889, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9243, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6822, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0449, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5048, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7519, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7132, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4194, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3365, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8191, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0753, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9652, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7825, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4780, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5458, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6440, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9186, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5542, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1988, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0841, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4462, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2076, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6779, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1667, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9635, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2893, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4676, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2350, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7948, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7082, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2256, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8081, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2499, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3595, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3543, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9652, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7215, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3592, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4075, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4071, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2311, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6125, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3039, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5690, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0769, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0899, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0230, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1900, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6982, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9640, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3723, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0289, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6457, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0319, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0649, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6525, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2012, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0273, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9074, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5155, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5910, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1113, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7342, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8861, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9459, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4912, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3687, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3490, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8917, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8589, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1309, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8600, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8397, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4996, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4544, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0623, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8283, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7415, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9817, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8029, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6703, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2747, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3303, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3317, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4920, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9870, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2014, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7335, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1097, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6006, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9433, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2395, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1524, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9889, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7406, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6495, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6680, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3028, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0245, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5959, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6613, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4418, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5690, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7669, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7520, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0095, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0959, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5044, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.6757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2059, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5613, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6539, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9766, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8335, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3874, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4134, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2391, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5605, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8952, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9139, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6589, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5971, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5794, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5297, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8339, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7827, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3028, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5075, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2706, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9534, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3113, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5193, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4028, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2931, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7504, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5060, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5262, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2449, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7282, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6605, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5926, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9339, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9748, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5723, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4055, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3255, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6815, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9529, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6766, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2276, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8301, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7701, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2446, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5485, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0828, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7012, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2721, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7465, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8184, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4920, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1861, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5457, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7635, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6822, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0854, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4388, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3928, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1347, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8254, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3676, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4975, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3865, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5070, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0724, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3524, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8420, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2640, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3467, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8722, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3868, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7887, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2134, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9949, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5454, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1373, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3221, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8728, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9785, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2471, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2900, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0539, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9747, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2543, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3751, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3721, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1352, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0446, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4603, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3868, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5248, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7168, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4163, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9142, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5765, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9237, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4388, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4793, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7322, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6544, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9862, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4317, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5493, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8916, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5459, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1822, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0310, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7648, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2534, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4352, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5140, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7683, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4230, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2292, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1113, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5862, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2624, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3081, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4976, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6001, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1093, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7596, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4953, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1112, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2659, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0976, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4655, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3724, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2882, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1785, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0827, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6703, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1414, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1332, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4421, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5428, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0303, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4679, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7331, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3133, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6645, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4851, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(10.2546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2460, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7331, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4438, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4054, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8020, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6370, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6581, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4436, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0282, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2131, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5519, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7910, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6255, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7013, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0068, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0751, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5667, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8865, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6000, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.9032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2137, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8364, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2094, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9407, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5621, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6650, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3519, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2722, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5866, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0380, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7331, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3434, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6080, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3622, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6373, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0812, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4449, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5854, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0536, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7897, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0139, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5080, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8592, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5556, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5729, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5213, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6942, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5949, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5704, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0461, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0923, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1152, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7982, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7029, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2280, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1193, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2667, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7409, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3927, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9649, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8616, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1320, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5140, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0137, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.7024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1289, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2766, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1838, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4780, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0320, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2911, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8262, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6046, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9543, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2967, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9747, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7935, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5871, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1436, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2145, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0781, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7410, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5110, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4438, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8430, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1352, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3594, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4864, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1460, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3094, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4136, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0537, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1063, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0371, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2046, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7338, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0533, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4942, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7740, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1862, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8715, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4110, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6556, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8467, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5788, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4005, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3046, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9079, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0007, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2438, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0667, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9937, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9074, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0301, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0761, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1107, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9389, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9482, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3719, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5687, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7140, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3421, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3273, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4020, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4072, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2521, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5763, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9688, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7659, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5215, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9683, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8953, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8059, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3354, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4749, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2708, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4659, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8932, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2246, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2744, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0604, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2648, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1690, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9765, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8765, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1773, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2141, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5188, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8761, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2963, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9644, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2204, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8174, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6341, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2254, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7156, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4393, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3675, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9815, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1009, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8373, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7044, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6785, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9954, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4081, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0017, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7197, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7014, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6224, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3360, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5036, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0731, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5168, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4124, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1435, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0568, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2175, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3736, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3495, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.2142, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9489, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7701, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0082, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4319, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9590, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6495, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4106, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2258, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3710, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8406, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3616, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5326, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0073, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9089, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6414, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4833, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9827, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8118, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0922, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0864, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3570, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8124, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9420, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3953, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1751, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6050, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8273, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8436, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6156, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9984, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6347, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8728, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2086, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6200, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1354, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8991, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6027, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8455, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5460, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1945, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3967, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6262, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6261, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4043, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8898, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1176, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2635, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2097, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8353, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1108, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2246, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7199, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8204, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1355, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8091, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9745, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0278, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7526, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7690, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7149, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2255, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7911, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0335, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2335, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7682, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7785, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7454, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(4.5443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6916, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1563, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7004, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4418, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7750, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4417, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7364, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8173, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2933, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5548, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5932, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6794, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2850, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2294, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8150, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0504, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6628, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7617, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4030, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7067, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0496, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5635, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8580, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3219, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4832, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0835, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6115, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1414, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7226, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8248, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2383, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4750, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3605, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4617, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8243, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7204, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2799, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1395, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9107, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3297, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7508, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1008, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9967, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1168, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8798, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3141, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.2226, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5996, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1992, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9930, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8975, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4703, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9433, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6616, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0365, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3128, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7029, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6493, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2562, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1163, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8895, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6071, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5781, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0338, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6623, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9356, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7051, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7066, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1243, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3079, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8694, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1302, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4428, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3753, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4822, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2397, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1750, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7734, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1126, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2675, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9085, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7445, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4589, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1129, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0821, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2002, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5175, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5666, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1585, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3326, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1988, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8724, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0921, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9589, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5224, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5429, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6301, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.4225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9854, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9181, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7094, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0141, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2629, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6156, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7191, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4679, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5015, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3706, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7431, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8310, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9854, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4704, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9941, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0716, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9967, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9808, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8868, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3657, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8680, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2727, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5929, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6218, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6407, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6313, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1853, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4961, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0275, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7604, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4728, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0487, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1597, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7749, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5836, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3109, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3906, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8410, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5062, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0815, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3453, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0976, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3208, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7132, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7443, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8306, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4924, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9059, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8123, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4245, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1710, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6214, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5919, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0371, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8076, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0284, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6064, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6167, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5719, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7022, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7650, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9762, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0265, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0566, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7700, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1289, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8702, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9536, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7032, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0042, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3754, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4314, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6959, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0273, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9328, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0363, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2995, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6731, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1474, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8734, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3434, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7702, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6595, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4626, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2479, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2817, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3414, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0841, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2749, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9232, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7768, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2927, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4168, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9456, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3367, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7886, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0755, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7737, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7846, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5712, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0058, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6250, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6425, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6124, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8934, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4736, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4023, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3190, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3037, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2944, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9136, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2874, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5801, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7025, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3577, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3720, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4585, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0063, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1147, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1595, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3198, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2581, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5303, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6152, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2969, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5420, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2154, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3397, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7406, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9932, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0157, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2360, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2812, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1679, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4797, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7973, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4709, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8772, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7901, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6601, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1334, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7159, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0117, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5647, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6650, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8082, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7506, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8262, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7657, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1565, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3760, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4718, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0775, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7314, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9400, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6337, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1204, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4837, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6605, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9319, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5867, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2607, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.8069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3178, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7539, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8461, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3017, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4286, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2595, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8067, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7649, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2349, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3340, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1711, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0514, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2468, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0525, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1941, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6121, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5039, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0121, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1287, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5298, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1885, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3518, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7896, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8339, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3557, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2285, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7508, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3056, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0388, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3300, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8508, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4702, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6972, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4722, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3447, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5108, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3534, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2498, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7037, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2005, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2126, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8951, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5504, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2705, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6400, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.1970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3542, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1747, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3121, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8019, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3331, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0134, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2753, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7971, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.8424, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0944, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2142, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1175, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4174, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4933, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6441, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4830, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4928, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2825, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2735, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2559, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6842, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1779, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9663, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2462, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8617, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5001, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8949, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4216, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5138, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8803, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3692, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4404, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0368, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7534, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0580, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6550, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9818, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5372, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3369, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6871, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6357, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0199, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7493, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2805, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8164, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6376, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4088, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2810, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5485, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4010, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3799, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5486, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3769, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2744, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0887, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1117, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7514, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0370, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1172, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2317, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1672, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3894, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2576, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9206, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3084, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4134, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4790, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2525, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6450, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.3614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8539, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5606, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.1016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2531, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1027, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8860, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3333, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8718, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8947, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9560, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0217, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1241, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4327, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6222, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5686, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4613, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6600, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5763, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9744, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5118, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7609, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7245, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6392, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2787, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3460, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5177, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6796, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1731, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1332, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1550, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0506, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7918, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2627, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7638, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7506, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0207, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0257, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4992, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0325, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2707, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9765, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1351, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9458, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6782, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7014, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9863, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0846, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1695, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4097, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7276, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1652, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4125, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5744, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2171, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9923, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9196, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5449, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2065, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7053, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9082, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6018, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5259, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1729, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5300, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2537, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1426, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3123, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7587, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1409, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1710, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5390, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6296, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9498, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9471, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9224, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9704, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1651, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1614, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0098, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7435, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7329, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5343, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8892, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8452, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1366, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3292, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8611, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7402, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2831, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4272, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6498, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4884, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6824, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7619, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8909, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4151, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3556, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5276, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3553, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2446, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6173, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2771, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1502, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2300, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.0143, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3119, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6648, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9732, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0494, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1299, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0588, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0511, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1074, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1131, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1792, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4748, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4817, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9415, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7677, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5537, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0738, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9646, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6547, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6050, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4652, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3722, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0578, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9634, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4849, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6762, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6024, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9482, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5761, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2532, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7150, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1940, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0828, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7813, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2386, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6288, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4596, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6448, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9185, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3764, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5385, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9166, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2998, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7220, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8108, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2293, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4499, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7247, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9083, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1530, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1387, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2861, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2113, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2324, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0910, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0858, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2552, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1727, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2133, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.4271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6246, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5608, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3539, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9090, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3462, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6091, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5200, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9903, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5620, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0488, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1150, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7656, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9515, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2865, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7540, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3074, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1459, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1313, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2454, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2380, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8767, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5266, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1348, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9999, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8463, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7558, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9484, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0223, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3500, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3323, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6572, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9282, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3516, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7799, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6606, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4491, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1049, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6382, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2847, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0418, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9784, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7554, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4461, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7103, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1839, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7875, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3505, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0697, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3243, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7492, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3987, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1661, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4195, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8127, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7961, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4483, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1768, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2574, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3907, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9240, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7641, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1225, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9694, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4087, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5290, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1936, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1227, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0165, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5072, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4786, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3252, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4988, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1100, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6628, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0660, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1545, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7632, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3938, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0763, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7538, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7105, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9521, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1925, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0752, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6758, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4507, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6960, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3668, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3561, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0840, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4762, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6664, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1532, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9148, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3844, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2888, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1228, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7630, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1639, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4341, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3466, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2811, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3319, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2000, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9497, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3989, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8480, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1708, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8021, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9714, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4332, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1743, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2522, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5406, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9274, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2541, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0737, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5465, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6061, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.5939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3774, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5034, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9295, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4059, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2400, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1405, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2873, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7637, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8439, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7480, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5745, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4916, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8748, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5680, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4893, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7913, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2583, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5685, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2251, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3902, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.7236, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3191, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0689, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6846, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4513, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9114, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1444, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0788, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9618, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.0130, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9308, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1781, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7026, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5761, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5642, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0281, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3699, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8134, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9209, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5378, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9458, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5814, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.6470, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7512, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.5462, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1696, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5680, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2144, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1986, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6665, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.6789, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8880, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0980, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7326, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0729, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7399, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.5672, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9585, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1756, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4816, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(9.3464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8027, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1618, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9222, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2047, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9321, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1778, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3416, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4883, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8317, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.9674, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9099, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4676, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4336, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0384, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3107, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8631, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7381, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8192, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9406, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2742, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9659, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4433, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3681, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2052, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2823, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1733, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6820, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9409, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2508, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2693, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.8817, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1108, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3843, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4255, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4260, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7819, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.3234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.6678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.4201, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.5045, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.9451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2158, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4200, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.8451, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0977, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.3016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3238, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2581, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0739, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.4111, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(5.7346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.4101, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5394, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8044, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.0234, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7618, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5976, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2379, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.8253, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.2459, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3036, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.2421, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.7269, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.1542, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.5698, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.9078, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.1908, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.3224, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.9183, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.7202, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.6795, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(6.2097, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(8.1242, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(7.0694, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SmoothL1LossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43msetting1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 86\u001b[0m, in \u001b[0;36mModelSettings.optimize_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# 모델 최적화\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 86\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# 변화도 클리핑 바꿔치기\u001b[39;00m\n\u001b[0;32m     88\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_value_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shhon\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    setting1.optimize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fffdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
