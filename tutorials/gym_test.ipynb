{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80dca1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4d9b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"ansi\"]} #, \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, size: int = 5, render_mode = \"human\"):\n",
    "        # The size of the square grid (5x5 by default)\n",
    "        self.size = size\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # Initialize positions - will be set randomly in reset()\n",
    "        # Using -1,-1 as \"uninitialized\" state\n",
    "        self._agent_location = np.array([-1, -1], dtype=np.int32)\n",
    "        self._target_location = np.array([-1, -1], dtype=np.int32)\n",
    "\n",
    "        # Define what the agent can observe\n",
    "        # Dict space gives us structured, human-readable observations\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"agent\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),   # [x, y] coordinates\n",
    "                \"target\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),  # [x, y] coordinates\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Define what actions are available (4 directions)\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "\n",
    "        # Map action numbers to actual movements on the grid\n",
    "        # This makes the code more readable than using raw numbers\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),   # Move right (positive x)\n",
    "            1: np.array([0, 1]),   # Move up (positive y)\n",
    "            2: np.array([-1, 0]),  # Move left (negative x)\n",
    "            3: np.array([0, -1]),  # Move down (negative y)\n",
    "        }\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \"\"\"Convert internal state to observation format.\n",
    "\n",
    "        Returns:\n",
    "            dict: Observation with agent and target positions\n",
    "        \"\"\"\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "    \n",
    "    def _get_info(self):\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            dict: Info with distance between agent and target\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        \"\"\"Start a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducible episodes\n",
    "            options: Additional configuration (unused in this example)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, info) for the initial state\n",
    "        \"\"\"\n",
    "        # IMPORTANT: Must call this first to seed the random number generator\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Randomly place the agent anywhere on the grid\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # Randomly place target, ensuring it's different from agent position\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size=2, dtype=int\n",
    "            )\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one timestep within the environment.\n",
    "\n",
    "        Args:\n",
    "            action: The action to take (0-3 for directions)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, reward, terminated, truncated, info)\n",
    "        \"\"\"\n",
    "        # Map the discrete action (0-3) to a movement direction\n",
    "        direction = self._action_to_direction[action]\n",
    "\n",
    "        # Update agent position, ensuring it stays within grid bounds\n",
    "        # np.clip prevents the agent from walking off the edge\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "\n",
    "        # Check if agent reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "\n",
    "        # We don't use truncation in this simple environment\n",
    "        # (could add a step limit here if desired)\n",
    "        truncated = False\n",
    "\n",
    "        # Simple reward structure: +1 for reaching target, 0 otherwise\n",
    "        # Alternative: could give small negative rewards for each step to encourage efficiency\n",
    "        reward = 1 if terminated else 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        res = [[\".\"] * self.size for _ in range(self.size)]\n",
    "        res[self._agent_location[0]][self._agent_location[1]] = \"a\"\n",
    "        res[self._target_location[0]][self._target_location[1]] = \"t\"\n",
    "        text = \"\\n\".join(\"\".join(line) for line in res)\n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            print(text)\n",
    "        elif self.render_mode == \"ansi\":\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3106f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"GridWorldEnv\",\n",
    "    entry_point=GridWorldEnv,\n",
    "    max_episode_steps=300,  # Prevent infinite episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b45bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      "...a.\n",
      "t....\n",
      ".....\n",
      ".....\n",
      "..t..\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "..a..\n",
      "Environment passes all checks!\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "env = gym.make(\"GridWorldEnv\")\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env.unwrapped)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf9c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
